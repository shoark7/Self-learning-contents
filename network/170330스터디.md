# 운영체제

## 3장 프로세스
오늘날의 컴퓨터 시스템들은 메모리에 다수의 프로그램들이 적재되어 병행 실행되는 것을 허용한다.  
이러한 발전은 다양한 프로그램을 보다 견고하게 제어하고 보다 구획화 할 것을 필요로 했다.  
이러한 필요성이 프로세스의 개념을 낳았으며, **프로세스**란 실행 중인 프로그램을 말한다.  
프로세스는 현대의 시분할 시스템에서 작업의 단위이다.  


하나의 시스템(컴퓨터 시스템)은 프로세스들의 집합체이다.  
CPU(또는 CPU들)는 이들 프로세스 가운데서 다중화(multiplexing)된다.  
CPU를 각 프로세스들 사이에게 전환시킴으로써, 운영체제는 컴퓨터를 보다 생산적으로 만든다.  
이 장에서는 프로세스는 무엇이며 어떻게 동작하는가를 논의한다.  

* 실행 중인 프로그램이고 모든 계산의 기초가 되는 프로세스의 개념을 소개한다.

* 스케줄링, 생성 및 종료등을 포함한 프로세스의 다양한 특성을 소개한다.  

* 공유 메모리와 메시지 전달 기법을 사용한 프로세스간 통신에 대해 탐구한다.  

* 클라이언트-서버 시스템에서의 통신에 대해 탐구한다.  

### 프로세스 개념
일괄처리 시스템에서는 Job이라는 용어를 즐겨 사용한다.  
반면에 시분할 시스템에서는 사용자 프로그램 또는 태스크를 가진다고 표현한다.  
그러나 여러가지 면에서 이들 모든 활동은 유사하다. 우리는 이들을 모두 프로세스라고 부른다.  

#### 정확히 프로세스는 무엇인가?
앞서 말했듯이 프로세스란 실행중인 프로그램이다. 하지만 좀 더 자세하게 알아보자.  
프로세스는 때로는 **텍스트 섹션**으로 알려진 프로그램 코드 이상의 무엇이다.  
프로세스는 또한 **프로그램 카운터**의 값과 **프로세서 레지스터의 내용(값)**으로 대표되는 현재 활동을 포함한다.  
(프로세서 레지스터의 값이라 함은 ISA(Instruction set architecture)가 정의한 각 논리 프로세서의 구조적 상태(architectural state)   
즉, **문맥(context)**을 뜻한다. 이는 데이터패스(Datapath)분류에 들어가는 레지스터 파일(register file) 장치가 구현하는  
외부로 노출된 레지스터 집합의 값들을 뜻한다. 자세한 내용은 하드웨어 부분을 참고하라.)  
프로세스는 일반적으로 함수의 매개변수, 복귀주소와 로컬 변수와 같은 임시적인 자료를 가지는 프로세스 **스택**과  
전역 변수들을 수록하는 **데이터 섹션**을 포함한다. 또한 프로세스는 프로세스 실행 중에 동적으로 할당되는 메모리인 **힙**을 포함한다.  


프로그램 그 자체는 명령어 리스트를 내용으로 가진 디스크에 저장된 파일(실행 파일)과 같은 수동적인 존재(passive entity)이다.  
프로세스는 다음에 실행할 명령어를 지정하는 프로그램 카운터와 관련 자원의 잡합을 가진 능동적인 존재(active entity)이다.  
두 프로세스들이 동일한 프로그램에 연관될 수 있지만, 이들은 두 개의 별도의 실행 순서로 간주된다.  
예를 들어 여러 사용자가 메일 프로그램의 서로 다른 복사본을 실행하거나, 또는 동일 사용자가 웹 브라우저 시스템의 복사본을 호출할 수 있다.  
이들 각각은 별도의 프로세스이며, 텍스트 섹션은 서로 같을 수 있어도 다른 섹션은 서로 다른 상태를 지닐 수 있다.  


또한 프로세스 자체가 다른 개체를 위한 실행 환경으로 동작할 수 있다는 사실에 주목하라.  
Java프로그래밍 환경이 좋은 예가 될 수 있다.  
이 개념은 다른 기계어로 작성된 프로그램이 아니라 JAVA언어로 작성된 프로그램을 실행시킨다는 점을 제외하면 모의실험과 동일한 개념이다.  

#### 프로세스 상태(Process State)
프로세스는 실행되면서 그 상태가 변한다. 프로세스의 상태는 부분적으로 그 프로세스의 현재의 활동에 따라서 정의된다.  

* new: 프로세스가 생성중

* running: 명령어들이 실행되고 있다.

* waiting: 프로세스가 어떤 사건(입출력 완료 또는 신호의 수신 같은)이 일어나기를 기다린다.  

* ready: 프로세스가 프로세서에 할당되기를 기다린다.  

* terminated: 프로세스의 실행이 종료되었다.  

이들의 이름은 임의적이고 운영체제마다 다르다. 다만,  
어느 한 순간에 한 프로세서상에는 오직 하나의 프로세스만이 실행된다는 것을 인식하는 것이 중요하다.  
그렇지만 많은 프로세스가 준비완료 및 대기 상태에 있을 수 있다.  

### 프로세스 제어 블록(PCB)
각 프로세스는 운영체제(운영체제 내부적으로 PCB를 이중 환형 연결리스트로 관리한다.)에서   
프로세스 제어 블록(PCB, Process Control Block)에 의해 표현된다.  
프로세스 제어 블록은 특정 프로세스와 연관된 여러 정보를 수록하며, 다음과 같은 것들은 포함한다.  

* 프로세스 상태

* 프로그램 카운터

* CPU 레지스터들

* CPU-스케줄링 정보

* 메모리 관리 정보

* 회계(accounting) 정보

* 입출력 상태 정보

상태는 위에서 언급한 내용과 같다.  


프로그램 카운터는 이 프로세스가 다으멩 실행할 명령어의 주소를 가리킨다.  
해당 프로세서의 아키텍처가 CISC인지 RISC인지에 따라서 단순하게 특정 상수를 더하거나,  
jump관련 명령어들만 고려해주면 될 수도 있고, 명령어에 따라서 따로따로 PC의 값을 다르게 더해주거나  
특정 명령어의 부작용으로 PC값이 변경될 수도 있다.  


CPU 레지스터는 컴퓨터의 구조에 따라 다양한 수와 타입을 가진다.  
레지스터에는 누산기(accumulator), 인덱스 레지스터, 스택 레지스터, 범용(general-purpose)레지스터들과 상태 코드(condition code) 정보가  
포함된다. 프로그램 카운터와 함께 이 상태 정보는, 나중에 프로세스가 계속 올바르게 실행되도록 하기 위해서, 인터럽트 발생 시 저장되어야 한다.  


CPU-스케줄링 정보는 프로세스 우선순위, 스케줄 큐에 대한 포인터와 다른 스케줄 매개변수들을 포함한다.  


메모리 관리 정보는 운영체제에 의해 사용되는 메모리 시스템에 따라 기준(base)레지스터와 한계(limit) 레지스터의 값,  
운영체제가 사용하는 메모리 시스템에 따라 페이지 테이블 또는 세그먼트 테이블 등과 같은 정보를 포함한다.  


회계 정보는 CPU 사용시간과 경과된 실시간, 시간 제한, 계정 번호, 잡 또는 프로세스 번호 등을 포함한다.  


입출력 상태 정보는 이 프로세스에게 할당된 입출력 장치들과 열린 파일의 목록등을 포함한다.  


요약하면 프로세스 제어 블록은 단순하게는 프로세스마다 달라지는 모든 정보를 저장하는 저장소의 역할을 한다.  
한가지 예를 들어보자, Linux에서는 PCB는 C 구조체인 task_struct로 표현된다. 그리고 이 구조체가 가지는 값은 다음과 같다.  

```{.c}
#include <linux/sched.h>

long state; /* 프로세스 상태 */
struct sched_entity se; /* 스케줄링 정보 */
struct task_struct *parent /* 이 프로세스의 부모 */
struct list_head children; /* 이 프로세스의 자식들 */
struct files_struct *files; /* 오픈 파일 */
struct mm_struct *mm; /* 이 프로세스의 주소 공간*/
```
시스템의 모든 프로세스는 커널 내부에서 PCB로 표현되고  
커널은 이 PCB들을 이중 환형 연결리스트로 관리한다.  
또한 커널은 현재 실행 중인 프로세스를 가리키는 포인터를 유지한다.  
get_current()를 매크로로 가려서 current심볼을 쓰면 커널은 현재 실행 중인 프로세스를 가리키는 포인터를 유지한다.  
예를 들어 현재 실행 중인 프로세스의 상태를 얻고 싶다면 다음과 같이 쓸 수 있다.  

```{.c}
current->state = new_state;
```

#### 스레드
현대적인 프로세서의 최소 실행단위는 사실 프로세스가 아니라 스레드이다.  
자세한 내용은 다음 시간에 다루도록 하겠다.  

### 프로세스 스케줄링
다중 프로그래밍의 목정은 CPU이용을 최대화 하기 위하여 항상 어떤 프로세스가 실행 되도록 하는데 있다.  
시분할의 목적은 각 프로그램이 실행되는 동안 사용자가 상호 작용할 수 있도록 프로세스들 사이에서 CPU를 빈번하게 교체하는 것이다.  
이 목적을 달성하기 위해 프로세스 스케줄러는 CPU에서 실행 가능한 여러 프로세스들 중에서 하나의 프로세스를 선택한다.  
단일 프로세서 시스템에서는 실행 중인 프로세스가 한 개 이상 있을 수 없다.  
만일 프로세스들이 여러 개가 있다면, 나머지 프로세스들은 CPU가 자유로워 다시 스케줄 될 때까지 대기해야 한다.  

#### 스케줄링 큐
프로세스가 시스템에 들어오면 이들은 **잡 큐**에 놓여진다.  
이 큐는 시스템 안의 모든 프로세스로 구성된다.  
주 메모리에 존재하며 준비 완료 상태에서 실행을 대기하는 프로세스들은 **준비 완료 큐**라 불리는 리스트 상에 유지된다.  
준비 완료 큐의 헤더는 리스트의 첫번째와 마지막 PCB를 가리키는 포인터를 포함한다.  
각 PCB는 준비 완료 큐에 있는 다음 프로세스를 가리키는 포인터 필드를 가진다.  


시스템에는 또한 다른 큐들도 있다. 예를 들어서,  
특정 입출력 장치를 대기하는 프로세스들의 리스트를 장치 큐(device queue)라고 한다.  
각 장치는 그 자신의 장치 큐를 가진다.  


프로세스 스케줄링의 공통적인 표현 방식은 큐잉 도표다.  
(그림은 책을 참조하라.) 각 사각형은 하나의 큐를 나타낸다.  
두 가지 타입의 큐(준비 완료 큐와 장치 큐들의 집합)가 존재한다.  
원은 큐를 서비스하는 자원이며, 화살표는 시스템에서 프로세스들의 흐름을 표현한다.  


새로운 프로세스는 처음에 준비 완료 큐에 놓인다. 프로세스는 실행을 위하여 선택 될 때   
즉, CPU를 할당받을(dispatch) 때 까지 준비 완료 큐에서 대기한다.  
일단 프로세스에 CPU가 할당되어 실행하면, 여러 가지 사건들 중의 하나가 발생할 수 있다.  

* 프로세스가 입출력 요청을 하여 입출력 큐에 넣어질 수 있다.  

* 프로세스가 새로운 자식 프로세스를 생성하고 자식 프로세스의 종료를 기다릴 수 있다.  

* 프로세스가 인터럽트의 결과에 의해 강제로 CPU에서 제거되고, 준비 완료 큐에 다시 놓일 수 있다.  

처음의 두 경우에서, 프로세스는 결국 대기 상태에서 준비 완료 상태로 전환되고, 다시 준비 완료 큐에 넣어지게 된다.  
프로세스는 종료될 때까지 이 주기를 계속하며, 종료되면 모든 큐에서 삭제되고 그 자신의 PCB와 자원을 반납한다.  
#### 스케줄러
프로세스는 일생 동안에 다양한 스케줄링 큐들 사이를 이주한다.  
운영체제는 어떤 방식으로든지 스케줄링 목적을 위해 프로세스들을 이들 큐에서 반드시 선택해야 한다.  
선택 절차는 적절한 스케줄러에 의하여 수행된다.  


일괄처리 시스템에서는 즉시 실행할 수 있는 것보다 더 많은 프로세스들이 종종 제출된다.  
이들 프로세스들은 대용량 메모리(전형적으로 디스크)에 저장되어 나중에 실행될 때까지 그곳에 유지된다.  
장기 스케줄러(또는 잡 스케줄러)는 이 풀에서 프로세스들을 선택하여 실행하기 위해 메모리로 적재한다.  
단기 스케줄러(또는 CPU 스케줄러)는 실행 중비가 오놔료되어 있는 프로세스들 중에서 선택하여, 이들 중 하나에게 CPU를 할당한다.  


이들 두 스케줄러 사이의 주요한 차이점은 이들의 실행빈도에 있다.  
단기 스케줄러는 보통 스케줄링 간격에 10~100밀리초 사이에 있는 것에 반해서  
장기 스케줄러는 다중 프로그램의 정도(메모리에 있는 프로세스들의 수, 잡 큐에 있는 프로세스의 수와는 다름)제어한다.  
다중 프로그램의 정도가 안정적이면, 평균 프로세스 생성률이 시스템을 떠나는 평균 프로세스 이탈률과 반드시 동일해야 한다.  
실행 간격이 비교적 크기 때문에, 장기 스케줄러는 실행할 프로세스를 선택하는데 시간을 더 사용해도 된다.  


장기 스케줄러가 신중한 선택을 하는 것이 중요하다. 일반적으로 대부분의 프로세스들은 입출력 중심 또는 CPU중심으로 묘사된다.  
**입출력 중심 프로세스**는 연산보다 입출력 실행에 더 많은 시간을 소요하는 프로세스다. 반면에,  
CPU 중심 프로세스는 입충역 중심 프로세스보다 연산에 시간을 더 소요하여, 입출력 요청을 드물게 발생시키는 프로세스다.  
따라서 장기 스케줄러는 입출력 중심과 CPU중심 프로세스들의 적절한 프로세스 혼합(mix)을 선택하는 것이 중요하다.  


어떤 시스템에서는 장기 스케줄러가 없거나 기능이 적다.  
예를 들어 UNIX와 MS Window같은 시분할 시스템들은 장기 스케줄러가 없다.  
시분할 시스템과 같은 일부 운영체제들은 추가로 중간 수준의 스케줄링을 도입한다.  
이와 같은 중기 스케줄러의 핵심 아이디어는 메모리에서(CPU를 위해 적극적으로 경쟁하는) 프로세스들을 제거함으로써  
다중 프로그래밍의 정도를 완화하는 것이 가끔 바람직 할 수 있다는 것이다.  
차후에 다시 프로세스를 메모리에서 불러와서 중단되었던 지점에서 부터 실행을 재개한다.  
이러한 기법을 스와핑이라고 한다. 프로세서는 중기 스케줄러에 의하여 스왑되어 나가고 후에 다시 스왑되어 들어온다.  


스와핑은 프로세스 혼합 상태를 개선하기 위하여 필요하기도 하며,  
메모리 요구에 대한 변화가 가용 메모리에 비해 너무 많은 요구를 수용하여,  
메모리를 자유화 시키기위하여 필요하기도 하다. 스와핑은 8장에서 논의 한다.  

#### 문맥 교환
인터럽트는 운영체제가 CPU를 현재 작업에서 빼앗아 커널 루틴을 실행할 수 있게 한다.  
이러한 연산은 범용 시스템에서 자주 발생한다.
문맥은 프로세스의 PCB에 표현된다. 문맥은 CPU레지스터의 값, 프로세스의 상태, 메모리 관리 정보등을 포함한다.  
일반적으로 커널 모드이건 사용자 모드이건 CPU의 현재 상태를 저장하는 작업을 수행하고(state save)   
나중에 연산을 재개하기 위하여 상태 복구 작업을 수행한다.   


CPU를 다른 프로세스로 교환하려면 이전의 프로세스 상태를 보관하고 새로운 프로세스의 보관된 상태를 복구하는 작업이 필요하다.  
이 작업은 문맥 교환(context switch)이라고 알려져 있다. 문맥 교환이 일어나면, 커널은 과거 프로세스의 문맥을 PCB에 저장하고  
실행이 스케줄된 새로운 프로세스의 저장된 문맥을 복구한다.  
문맥 교환이 진행될 동안 시스템이 아무런 유용한 일을 목하기 때문에 문맥 교환 시간은 순수한 오버헤드이다.  
그리고 운영체제에 따라서 복잡한 메모리 관리 기법을 지원할 수도 있고, 아닐 수도 있는데 만약 지원한다면  
각 프로세스마다 유지해야 하는 문맥의 종류와 양이 증가하여 문맥 교환시 해야 할 작업의 양이 많아진다.  
이는 오버헤드의 증가로 이어진다.  

### 프로세스에 대한 연산
이 부분은 다음 시간에 하도록 한다.  

### 프로세스간 통신
운영체제 내에서 실행되는 병행 프로세스들은 독립적이거나 또는 협력적인 프로세스들일 수 있다.   
프로세스가 시스템에서 실행 중인 다른 프로세스들에게 영향을 주거나 받지 않는다면 독립적인 프로세스라고 말한다.  
다른 프로세스와 데이터를 공유하지 않는 프로세스는 독립적이다.  
프로세스가 시스템에서 실행중인 다른 프로세스들에게 영향을 주거나 받는다면 이는 협력적인 프로세스이다.  
프로세스 협력을 허용하는 환경을 제공하는 데는 몇가지 이유가 있다.

* 정보 공유: 
여러 사용자가 동일한 정보(예를 들면 공유 파일등)에 흥미를 가질 수 있으므로,   
그러한 정보를 병행적으로 접근할 수 있는 환경을 제공해야 한다.  


* 계산 가속화: 
만일 우리가 특정 태스크(task)를 빨리 실행하고자 한다면, 우리는 그것을 서브태스크로 나누어,  
이들 각각이 다른 서브태스크들과 병렬로 실행되게 해야 한다. 이러한 가속화는 복수 개의 처리 코어를 가진 경우만 가능하다.  


* 모듈성:
우리가 2장에서 논의 했던 것 같이, 우리는 시스템 기능을 별도의 프로세스들 또는 스레드들로 나누어,  
모듈식 형태로 시스템을 구성하기를 원할 수 있다.


* 편의성:
개별 사용자들이 한 순간에 작업할 많은 태스크를 가질 수도 있다.  
예를 들면 한 사용자가 편집, 음악 듣기 및 컴파일 작업을 병렬로 할 수 있다.  


협력적 프로세스들은 데이터와 정보를 교환할 수 있는 프로세스간 통신(IPC)기법을 필요로 한다.  
프로세스간 통신에는 기본적으로 공유 메모리와 메시지 전달의 두가지 모델이 있다.  
대체로 많은 시스템에서 두 모델을 구현하고 있다.  


대체로 공유 메모리 모델이 메시지 전달 모델(대체로 시스템 호출을 사용하여 구현되므로 기본적으로 많은 오버헤드를 수반한다.)  
보다 더 빠른 경향을 보이지만 프로세서 코어가 많아질 수록 캐시 효율성이 떨어지는 문제로 인해서  
공유 메모리보다 메시지 전달 모델이 더 선호된다.  


#### 공유 메모리 시스템
공유 메모리를 사용하는 프로세서간 통신에는 통신하는 프로세스들이 공유 메모리 영역을 구축해야 한다.  
통상 공유 메모리 영역은 공유 메모리 세그먼트를 생성하는 프로세스의 주소 공간에 위치한다.  
이 공유 메모리 세그먼트를 이용하여 통신하고자 하는 다른 프로세스들은 이 세그먼트를 자신의 주소 공간에 추가하여야 한다.  
일반적으로 운영체제는 한 프로세스가 다른 프로세스의 메모리에 접근하는 것을 금지한다는 것을 기억하라.  


데이터의 형식과 위치는 이들 프로세스들에 의해 결정되며 운영체제의 소관이 아니다.  
또한 프로세스들은 동시에 동일한 위치에 쓰지 않도록 책입져야 한다.  
협력하는 프로세스의 개념을 설명하기 위해서, 협력하는 프로세스의 일반적인 패러다임인 생산자-소비자 문제를 생각해보자.  
생산자 프로세스는 정보를 생산하고 소비자 프로세스는 정보를 소비한다. 예를 들어 컴파일러는 어셈블리 코드를 생산하고,  
어셈블러는 이것을 소비한다. 생산자 소비자 문제는 클라이언트 서버 패러다임을 위한 유용한 은유를 제공한다.  
일반적으로 우리는 서버를 생산자로 클라이언트를 소비자로 생각한다. 예를 들면 웹 서버는 HTML파일과 이미지를 생산하고(제공하고)  
이 자원들을 요청한 클라이언트 웹 브라우저가 소비하게 된다.(즉, 읽는다.)  


생산자-소비자 문제의 하나의 해결책은 공유 메모리를 사용하는 것이다.  
생산자와 소비자 프로세스들이 병행으로 실행되도록 하려면,  
생산자가 정보를 채워넣고 소비자가 소모할 수 있는 항목들의 버퍼가 반드시 사용가능해야 한다.  
이 버퍼는 생산자와 소비자가 공유하는 메모리 영역에 존재하게 된다.  


두 가지 유형의 버퍼가 사용된다. 무한 버퍼(unbounded buffer)의 생산자 소비자 문제에서는 버퍼의 크기에 실질적인 한계가 없다.  
소비자는 새로운 항목을 기다려야만 할 수도 있지만, 생산자는 항상 새로운 항목을 생산할 수 있다.  
유한 버퍼(bounded buffer)는 버퍼의 크기가 고정되어 있다고 가정한다. 이 경우 버퍼가 비어 있으면 소비자는 반드시 대기해야 하며,  
모든 버퍼가 채워져 있으면 생산자가 대기해야 한다.  
#### 메시지 전달 시스템
프로세스간 통신(데이터를 주고 받는)을 하는 또 다른 방법은 운영체제가 메시지 전달 유틸리티를 통하여 서로 협력하는  
프로세스간의 통신 수단을 제공해 주는 방법이 있다.  


나머지는 다음 시간에 

### 클라이언트-서버 간 통신
이전 절에서 공유 메모리와 메시지 전달 기법을 사용하여 프로세스들이 통신하는 방법에 대해 설명하였다.
이 기법들은 클라이언트 서버 시스템의 통신에도 사용할 수 있다.  
이 절에서는 클라이언트 서버에서 사용할 수 있는 세 가지 다른 통신 전략에 대해서 설명한다.  
이 세가지는 소켓, 원격 프로시저 호출(RPCs) 및 파이프이다.

#### 소켓
다음 시간에

#### 원격 프로시저 호출

#### 파이프
다음 시간에 

### 요약


## 5장 프로세스 스케줄링
CPU 스케줄링은 다중 프로그램 운영체제의 기본이다. 운영 체제는 CPU를 프로세스들 간에 교환함으로써  
컴퓨터를 보다 생산적으로 만든다. 이 장에서 우리는 기본적인 스케줄링 개념을 소개하고, 서로 다른 여러가지 스케줄링 알고리즘을 제시한다.  
또한 특정 시스템을 위해 알고리즘을 선택하는 문제도 고려한다.  

* 다중 프로그래 운영체제의 기반인 CPU 스케줄링을 소개한다.  

* 다양한 CPU 스케줄링 알고리즘을 설명한다.  

* 특정 시스템을 위한 CPU 스케줄링 알고리즘을 선택하는 평가 기준을 논의한다.  

* 몇몇 운영체제의 스케줄링 알고리즘을 분석한다.

### 기본 개념
단일 프로세서 시스템에서는 한 순간에 오직 하나의 프로세스만이 실행될 수 있다.  
나머지 프로세스는 CPU가 자유 상태가 되어 다시 스케줄 될 수 있을 때까지 기다려야 한다.  
다중 프로그래밍의 목적은 CPU이용률을 최대화 하기 위해 항상 실행중인 프로세스를 가지게 하는데 있다.  
다중 프로그래밍에 대한 기본 아이디어는 비교적 간단하다.  
하나의 프로세스는 전형적으로 어떤 입출력 요청이 완료되를 기다려야만 할 때까지 실행된다.  
이렇게 되면 어떤 유용한 작업도 수행하지 못한다. 다중 프로그래밍에서는, 우리는 이러한 시간을 생산적으로 활용하려고 시도한다.  
어느 한 순간에 다수의 프로세스들을 메모리 내에 (**즉, 동시에**)유지한다.  
이 정도를 다중 프로그램의 정도, 다중 프로그래밍의 정도라고 한다.  


어떤 프로세스가 대기해야 할 경우, 운영체제는 CPU를 그 프로세스로부터 회수해 다른 프로세스에 할당한다.  
이러한 패턴은 계속된다. 하나의 프로세스가 대기해야 할 때마다, 다른 프로세스가 CPU사용을 양도받을 수 있다.  
이러한 종류의 스케줄링은 운영체제의 기본적인 기능이다. 거의 모든 컴퓨터 자원들은 사용되기 전에 스케줄된다.  
물론 CPU는 중요한 컴퓨터 자원 중의 하나이다. 따라서 CPU의 스케줄링은 운영체제 설계의 핵심이 된다.  

#### CPU-입출력 버스트 사이클
cpu 스케줄링의 성공은 프로세스들의 다음과 같은 관찰된 성질에 의해 좌우된다.  
프로세스 실행은 CPU실행과 입출력 대기의 사이클로 구성된다. 프로세스들은 이들 두 상태 사이를 교대로 왔다 갔다 한다.  
프로세스의 실행은 CPU버스트로 시작된다. 뒤이어 입출력 버스트가 발생하고 그 뒤를 이어 또 다른 CPU버스트가 발생하며,  
또 다른 입출력 버스트 등등으로 진행된다. 결국 마지막 CPU버스트는 또 다른 입출력 버스트가 뒤따르는 대신  
실행을 종료하기 위한 시스템 요청과 함께 끝난다.  


입출력 지향 프로그램은 전형적으로 짧은 CPU버스트를 많이 가질 것이다.  
CPU지향 프로그램은 다수의 긴CPU버스트를 가질 수 있다.  
이러한 분포는 적절한 CPU 스케줄링 알고지름을 선택하는 데 매우 중요할 수 있다.  

#### CPU 스케줄러
CPU가 유휴 상태가 될 때마다, 운영체제는 준비 완료 큐에 있는 프로세스들 중에서 하나를 선택해 실행해야 한다.  
선택 절차는 단기(short term)스케줄러에 의해 수행된다. 스케줄러는 실행 준비가 되어 있는 메모리 내의 프로세스들 중에서 선택하여,  
이들 중 하나에게 CPU를 할당한다. **준비 완료 큐는 반드시 선입 선출 방식의 큐가 아니어도 되는 것에 유의해야 한다.**  
여러 가지 스케줄링 알고리즘들을 고려할 때 알게 되겠지만, 준비 완료 큐는 선입 선출 큐, 우선순위 큐, 트리 또는 단순히 순서가 없는  
연결 리스트로 구현할 수 있다. 그러나 개념적으로 볼 때 준비 완료 큐에 있는 모든 프로세스들은 CPU에서 실행될 기회를 기다리며  
대기하고 있다. 큐에 있는 레코드들은 일반적으로 프로세스들의 프로세스 제어 블록(PCB)들이다.  

#### 선점 스케줄링
CPU 스케줄링의 결정은 다음의 네 가지 상황하에서 발생할 수 있다.  

1. 한 프로세스가 실행 상태에서 대기 상태로 전환될 때(예를 들어 입출력 요청이나 자식 프로세스가 종료되기를 기다리며 wait()를 호출한다.) 

2. 프로세스가 실행 상태에서 준비 완료 상태로 전환될 때(예를 들어 인터럽트가 발생할 때)

3. 프로세스가 대기 상태에서 준비 완료 상태로 전환될 때(예를 들어 입출력의 종료 시)

4. 프로세스가 종료할 때  

상황 1과 4의 경우, 스케줄링 면에서는 선택의 여지가 없다.  
실행을 위해 새로운 프로세스(준비 완료 큐에 하나라도 존재할 경우)가 반드시 선택되어야 한다.  
그러나 상황2와 3을 위해서는 선택의 여지가 있다.  


상황 1과 4에서만 스케줄링이 발생할 경우, 우리는 이러한 스케줄링 방법을 비선점(non-preemptive)또는 협조적이하고 한다.  
그렇지 않다면, 그것은 선점(preemtive)이라고 한다. 비선점 스케줄링 하에서는,  
일단 CPU가 한 프로세스에 할당되면 프로세스가 **자발적으로** 종료하던지 또는 대기 상태로 전환해 CPU를 방출할 때까지 CPU를 점유한다.  


이와 대척점에 있는 것이 바로 선점 스케줄링 방법이다. 선점형 스케줄링은 어떤 프로세스가 할당받아 실행중에 있어도  
다른 프로세스가 실행 중인 프로세스를 중지하고 **커널이 CPU를 강제로 점유할 수 있다.**   
모든 프로세그에게 CPU사용 시간을 동일하게 부여할 수 있다.  
빠른 응답시간을 요하는 대화식 시분할 시스템에 적합하며 긴급한 프로세서를 제어할 수 있다.  
**운영체제가 프로세서 자원을 선점**하고 있다가 각 프로세스의 요청이 있을 떄 특정 요건들을 기준으로 자원을 배분하는 방식이다.
불행하게도 선점 스케줄링은 데이터가 다수의 프로세스에 의해 공유될 때 경쟁 조건을 초래할 수 있다.  


보충 필요

#### 디스패처
CPU 스케줄링 기능에 포함된 또 하나의 요소는 디스패처(dispatcher)이다.  
디스패처는 CPU의 제어를 단기 스케줄러가 선택한 프로세스에게 주는 모듈이며 다음과 같은 작업을 포함한다.  

* 문맥을 교환하는 일

* 사용자 모드로 전환하는 일

* 프로그램을 다시 시작하기 위해 사용자 프로그램의 적절한 위치를 이동(jump)하는 일

디스패처는 모든 프로세스의 문맥 교환 시 호출되므로, 가능한 최고로 빨리 수행되어야 한다.  
디스패처 하나의 프로세스를 정지하고 다른 프로세의 수행을 시작하는 데까지 소요되는 시간을 **디스패치 지연**이라고 한다.

### 스케줄링 기준
서로 다른 CPU스케줄링 알고리즘들은 다른 특성을 가지고 있으며 한 부류의 프로세스들을 다른 부류보다 더 선호할 수 있다.  
특정 상황에서 어떠한 알고리즘을 선택하려면, 우리는 다양한 알고리즘들의 서로 다른 특성을 반드시 고려해야 한다.  


다음은 CPU 스케줄링 알고리즘을 비교하기 위한 여러 기준이다.  
비교하는데 사용되는 특성에 따라서 최선의 알고리즘을 결정하는 데 큰 차이가 발생한다. 사용되는 기준은 다음을 포함한다.  

* CPU 이용률:
우리는 가능한 CPU를 최대한 바쁘게 유지하기를 원한다.  
개념상으로 CPU이용률은 0에서 100퍼센트까지 이른다. 실제 시스템에서는 40퍼센트에서(부하가 적은 시스템의 경우)  
90퍼센트까지의(부하가 큰 시스템의 경우) 범위를 가져야 한다.  


* 처리량(throuput):  
CPU가 프로세스를 수행하느라고 바쁘다면, 작업이 진행되고 있는 것이다.  
작업량 측정의 한 방법은 단위 시간당 완료된 프로세스의 개수로, 이것을 처리량이라고 한다.  
긴 프로세스인 경우에는 이 비율이 시간단 1개의 프로세스가 될 수 있고  
짧은 트랜잭션인 경우 처리량은 초당 10개의 프로세스가 될 수도 있다.  


* 총처리 시간(turnaround time):  
특정한 프로세스의 입장에서 보면, 중요한 기준은 그 프로세스를 실행하는 데 소요된 시간일 것이다.  
프로세스의 제출 시간과 완료 시간의 간격을 총처리 시간이라고 한다.  
총처리 시간은 메모리에 들어가기 위해 기다리며 소비한 시간, 준비 완료 큐에서 대기한 시간, CPU에서 실행하는 시간,  
그리고 입출력 시간을 합한 시간이다.


* 대기 시간:
CPU 스케줄링 알고리즘은 프로세스가 실행하거나 입출력을 하는 시간의 양에 영향을 미치지 않는다.  
스케줄링 알고리즘은 단지 프로세스가 준비 완료 큐에서 대기하는 시간의 양에만 영향을 준다.   
대기 시간은 준비 완료 큐에서 대기하면서 보낸 시간의 합이다.  

* 응답 시간:
대화식 시스템(interactive system)에서, 총 처리 시간은 최선의 기준이 아닐 수도 있다.  
프로세스가 어떤 출력을 매우 일찍 생성하고, 앞서의 결과가 사용자에게 출력되는 사이에 새로운 결과를 얻으려고 연산을 계속하는 경우가 종종 있다.  
따라서 또 다른 기준은 하나의 요구를 제출한 후 첫 번째 응답이 나올 때까지 걸린 시간이다.  
**총처리 시간은 일반적으로 출력 장치의 속도에 의해 제한된다.**  

### 스케줄링 알고리즘
다음 시간에 
### 스레드 스케줄링

다음 시간에 
### 멀티 프로세서 스케줄링

다음 시간에 
### 실시간 CPU 스케줄링

다음 시간에 
### 사례:Linux 스케줄링

다음 시간에 
## 8장 메모리 관리 전략
5장에서는 CPU가 여러 프로세스에 의해 어떻게 공유되는지를 설명하였고   
CPU스케줄링으로 CPU의 이용률이 어떻게 향상될 수 있으며, 또 응답 속도가 어떻게 개선될 수 있는지를 설명하였다.  
그러나 성능을 향상시키기 위해서는 주 메모리에 여러 개의 프로세스가 올라와 있어야 한다.  
즉, 여러 프로세스들이 주 메모리를 공유해야 한다.  


특정 메모리 관리 기법 및 시스템의 선택은 많은 요인에 의해 좌우되는데, 특히 그 시스템의 하드웨어 디자인에 영향을 많이 받는다.  
많은 알고리즘은 하드웨어 지원을 필요로 하기 때문에 많은 시스템들에서 하드웨어와 운영체제 메모리 관리가 밀접하게 결합되어 있다.  


* 메모리 하드웨어를 구성하는 다양한 방법을 자세히 기술한다.  

* 프로세스에게 메모리를 할당하는 다양한 기법들을 탐구한다.  

* 현대 컴퓨터 시스템에서 페이징의 동작 방법에 대해서 자세하게 논의 한다.

### 기본 개념

먼저 용어를 하나 정의하고 가자, 사이클이라는 용어가 계속 나오는데 완전히 맞다고 할 수는 없지만  
예를 들어 3GHZ 싱글 코어 CPU가 있다고 하면, 해당 CPU는 초당 30억 사이클을 제공할 수 있다는 뜻이 된다.  


주 메모리는 현대 컴퓨터 시스템의 운영에 중심적인 역할을 한다.  
메모리는 각각 주소가 할당된 일련의 바이트들로 구성된다. CPU는 PC(Program counter)가 지시하는 대로  
다음 수행할 명령어를 가져오는데 그 명령어는 필요한 경우 추가적인 데이터를 더 가져올 수 있으며  
반대로 데이터를 내보낼 수도 있다. 


전형적인 명령어 실행은 먼저 메모리로부터 한 명령어를 가져오는것 부터 시작한다.  
그 다음 명령어를 해독하고, 메모리에서 피연산자(operand)를 가져와  
피연산자에 대해 명령어를 실행한 후에 계산 결과를 메모리에 다시 저장한다.  
메모리는 주소에 지시한 대로 읽기, 쓰기만 할 뿐 이 주소들이 어떻게 생성되었는지(명령어 계수기, 인덱싱, 간접 및 문자 주소 등)  
혹은 그 주소가 가리키는 내용이 무엇인지(데이터 혹은, 명령어)를 모른다. 따라서 주소가 프로그램에 의해서 어떻게 생성 되었는지에 대한   
세부 사항은 이 시점에서의 고려 대상이 아니다. 여기서는 프로그램에 의해서 생성되는 일련의 주소만 언급한다.  

#### 기본 하드웨어
주 메모리와 프로세서 자체에 내장되어 있는 레지스터들은 **CPU가 직접 접근할 수 있는 유일한 범용 장치이다.**  
기계 명령어들은 메모리 주소만들 인수로 취하고, 디스크의 주소를 인수로 취하지 않는다.  
따라서 모든 실행되는 명령어와 데이터들은 CPU가 직접적으로 접근할 수 있는 주 메모리와 레지스터에 있어야 한다.    
만약 데이터가 메모리에 없다면 CPU가 그 것들을 처리하기 전에 메모리로 이동시켜야 한다.  


CPU에 내장되어 있는 레지스터들은 일반적으로 CPU 클록(clock)의 1 사이클 내에 접근이 가능하다.  
대부분의 CPU들은 레지스터에 있는 명령어의 해독과 간단한 오퍼레이션을 클록 틱(clock tic)당 하나 또는 그 이상의 속도로 처리한다.  
그러나 메모리 버스를 통해 전송되는 주 메모리의 경우는 앞에서 언급했던 상황과는 다르다. 
주 메모리의 접근을 완료하기 위해서는 많은 CPU 클록 틱 사이클이 소요되며, 
이 경우 CPU가 데이터가 없어서 명령어를 수행하지 못하고 지연되는(stall) 현상이 발생하게 된다.  


물리 메모리의 상대적인 접근 속도의 차이를 고려하는 것에 추가로 올바은 동작을 보장해야만 한다.  
시스템이 올바르게 동작하기 위해서는 사용자 프로그램으로부터 운영체제 영역을 보호햐야 한다.  
다중 사용자 시스템인 경우 추가적으로 다른 사용자 프로그램이 특정 사용자 프로그램을 접근하는 것을 막는 것도 함께 이루어져야 한다.  
운영체제가 CPU와 메모리 간의 접근 중에 개입하게 되면 성능이 떨어지기 때문에 이러한 보호 기법은 반드시 하드웨어의 지원이 있어야 한다.  
앞으로 이 장에서 설명할 방법 외에도 많은 다른 구현 방법들이 있지만, 여기서는 하나의 구현 방법에 대한 개요만을 설명한다.  


**먼저 각각의 프로세스가 독립된 메모리 공간을 가지도록 보장해야 한다.**  
가장 간단한 방법은 프로세스의 레지스터에 기준과 상한(base and limit)이라고 불리는 두 개의 레지스터를 사용해 
적법한 영역과 불법적인 영역(legal and illegal)을 구분할 수 있다. 불법적인 영역의 접근이 감지되면 trap을 발생시킨다.  


기준과 상한 레지스터는 여러 가지 특권 명령을 사용하는 운영체제에 의해서만 로드(load)된다.  


커널 모드에서는 수행되는 운영체제는 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 어떠한 제약도 받지 않는다.  
이러한 원칙 때문에 운영체제는 사용자 영역 메모리 영역에 적재, 오류가 발생한 경우에 그 프로그램을 덤프,  
시스템 호출의 매개변수를 변경, 사용자 메모리로부터의 입출력과 다른 많은 서비스들을 제공할 수 있다.  
예를 들어 다중 처리기 시스템 운영체제는 한 프로세스의 상태를 레지스터로부터 메인 메모리로 저장하고  
다음 프로세스의 문맥을 메인 메모리로부터 레지스터로 저장하는 문맥 교환을 반드시 실행해야 한다.  

#### 주소의 할당(address binding)
링커나 로더가 많은 역할을 담당한다.


전통적으로 메모리 주소 공간에서 명령어와 데이터의 바인딩은 그 바인딩이 이루어 지는 시점에 따라 다음과 같이 구분된다.  

* 컴파일 시간(compile time) 바인딩

* 적재 시간(load time) 바인딩

* 실행 시간(execution time) 바인딩

#### 논리 주소 공간 VS 물리 주소 공간
CPU가 생성하는 주소를 일반적으로 논리 주소(logical address)라 하며,   
반면에 메모리가 취급하게 되는 주소(즉, 메모리 주소 레지스터(MAR)에 주어지는 주소)는  
일반적으로 물리 주소(physical address)라고 한다.  


앞의 바인딩 분류에서 언급했던 컴파일 시 바인딩 과 적재 시의 바인딩 기법의 경우에는  
논리, 물리 주소가 같다. 그러나 실행 시간 바인딩 기법에서는 논리, 물리 주소가 다르다.  
이러한 경우에는 논리 주소를 가상 주소(virtual address)라고 한다. 여기서는 논리 주소나 가상 주소나 같은 뜻으로 사용한다.  
프로그램에 의해 생성된 모든 논리 주소 집합을 논리 주소 공간(logical address space)라고 하며  
이 논리 주소와 일치하는 모든 물리 주소 집합을 물리 주소 공간(physical address space)라고 한다.  


프로그램 실행 중에는 이와 같은 가상 주소를 물리 주소로 바꿔줘야 하는데, 이 변환 작업은 하드웨어 장치인 메모리 관리기(MMU)에 의해 실행된다.  
우선 여기에서는 앞서 설명한 기준 레지스터 기법을 일반화 시킨 아주 단순한 MMU기법에 의한 변환을 설명할 것이다.  


보충 필요

#### 동적 적재(Dynamic Loading)
동적 적재는 운영체제로 부터 특별한 지원을 필요로 하지 않는다. 사용자 자신이 프로그램의 설계를 책임져야 한다.   
운영체제는 동적 적재를 구현하는 라이브러리 루틴을 제공해 줄 수는 있다.  
#### 동적 연결 및 공유 라이브러리
정적 연결, 스텁, 공유 라이브러리 <- 보충 필요  

### 스와핑

#### 기본 스와핑

### 연속 메모리 할당

#### 메모리 보호

#### 메모리 할당

#### 단편화
외부 단편화와 내부 단편화에 대해서 설명할 것

### 세그먼테이션

#### 기본 방법

#### 하드웨어

### 페이징

#### 기본 방법

#### 하드웨어 지원

#### 보호

#### 공유 페이지

### 페이지 테이블의 구조
다음 시간에 

### 요약

## 9장 가상메모리
170316스터디.md에 자세하게 나와있다. 참고하라.

# 하드웨어

## 개괄
하드웨어를 공부하면 내부적으로 어떻게 돌아가고 있는지 알게 되어 좀 더 효율적인 코드를 만드는데 도움이 된다.  
또한 디버깅을 할 때도 문제가 왜 일어났는지 밑바닥부터 생각하여 보다 근본적으로 문제를 해결할 수 있게된다.  


여기에 더해 하드웨어는 복잡한 전자회로만 가득한 과목이 아니라, 각종 소프트웨어 알고리즘들이 하드웨어로 구현되어 있을 알 수 있을 것이다.  
이런 알고리즘들을 익히면 보다 빠른 프로그램을 만드는데 큰 도움을 받을 수 있다.  
예를 들어, 현대 프로세서의 기본 기술인 파이프라인은 대표적인 병렬 프로그래밍 방법론이다.  


프로세서는 명령어 사이의 의존성을 분석해 명령어 처리율을 높일 수 있는데, 의존성 분석은  
컴파일러나 소프트웨어 테스팅에서, 병렬 프로그램에서도 기본적인 개념이다.  


컴퓨터 성능에 결정적인 영향을 미치는 캐시는 웹 브라우저 캐시, 운영체제의 각종 캐시 등으로  
웹 서버에서 아주 손쉽게 찾아볼 수 있다. 캐시에 적용되는 여러 정책도 흡사한 면이 많다.  
멀티코어 시스템에서는 캐시 관리가 더 어려워 지는데 이 문제는 서버 시스템에서도 고스란히 볼 수 있다.  


현대 프로세서에는 분기 예측기라는 컴포넌트가 필수적으로 들어가 있다.  
이 분기 예측기의 알고리즘 역시 캐시처럼 소프트웨어적인 아이디어로 만들어져 있다.  
프로그램이 미래에 보일 행동을 과거 사실을 분석해 예측하는 알고리즘은 얼마든지 여러분의 프로그램에 적용될 수 있다.  
프리펫칭은 운영체제에서도 쉽게 찾아볼 수 있다.  


또한 병렬 프로그래밍을 잘 하려면 (특히 스레드 API를 통해서)하드웨어에 대한 이해는 필수이다.  
또 하나 흥미로운 사실은 그래픽 분야에서 쓰였던 그래픽 카드의 GPU가 이제 프로세서처럼  
일반적인 계산을 하는 강력한 연산장치로 대두하고 있다는 점이다.  


## ISA, RISC, CISC

### Instruction set Architecture: 명령어 집합 구조
프로세서를 이해하여면 프로세서가 쓰는 언어를 알아야만 한다.  
능숙하게 그 언어를 다뤄야 할 필요는 이제 많이 줄었지만 최소한 그 언어가 어떤 모습인지는 알아야 프로세서를 깊이 알 수 있다.  
컴파일러가 없다다면 프로그래머는 프로세서가 이해하는 기계어 혹은 어셈블리어를 이용해야 컴퓨터에 작업을 지시할 수 있다.  
이 기계어가 명령어 집합 구조이며, 줄여서 ISA로 표현한다.  


ISA가 서로 다른 프로세서라면 해당 ISA로 만들어진 프로그램은 곧바로 동작할 수 없다.  
새롭게 컴파일을 하거나 에뮬레이션을 거쳐야만 한다.  
참고로 프로세서가 이해하는 명령어 하나하나를 인스트럭션이라고 부른다.  


또한 ISA는 명령어 종류, 피연산자 타입, 레지스터 개수, 인코딩 방법등 여러가지를 정의한다.  
그 외에 실제로 프로그램이 돌아가려면 ISA위에 ABI(Application Binary Interface)라는  
응용 프로그램과 운영체제 사이의 약속도 필요하다. 
함수 호출 규약(Calling Convetions)이나 바이너리 포맷에 대한 규약이 대표적이다.  

### Reduced Instruction set computer
비교적 싼 가격, 단순한 명령어 디코더, 정적인 명령어 길이, 더 많은 범용 레지스터 개수, 단순한 명령어 집합  
하드웨어의 복잡함을 소프트웨어가 처리한다. (컴파일러에게 그 책임을 넘겼다.)  

### Complex Instruction set computer:
복잡한 명령어 디코더, 가변적인 명령어 길이, 풍부한 표현력, 더 적은 범용 레지스터 개수, 복잡한 명령어 집합  
컴퓨터 프로그램의 복잡함을 하드웨어가 도맡아 처리한다.  


### 그러나...
하지만 이런 단순한 비교는 현대 컴퓨터에 통하지 않는 말이다.  
CISC로 대표되는 x86프로세서의 경우에도 micro-op이라고 하는 RISC형태의 표현으로 바뀌어서 명령어를 하나씩 수행한다.  

## 프로세서의 기본적인 부품과 개념들

### ALU, 쉬프트 레지스터, 논리 레지스터

### 시스템 버스

### 데이터패스 계열 

### 컨트롤 유닛 계열

## 암달의 법칙과 프로세서의 성능 지표

## 의존성

## 프로세서의 기본 동작

## 명령어 파이프라인

## 비순차 실행

## 하이퍼스레딩(멀티스레딩)

## 캐시

# 몇 가지 짚고 넘어가야 할 각종 용어들

1. 처리율
단위 시간 완료된 프로세스의 개수  
파이프라인으로 개선할 수 있다.  


2. 레이턴시
하나의 프로세스를 얼마나 빠르게 완료하는가?  
캐시로 개선할 수 있다.  


3. 대역폭
단위 시간당 데이터의 최대 용량을 뜻한다.  
예를 들어 1Gbps는 1초당 최대 1기가 비트 데이터를 전송할 수 있는 대역폭을 가지고 있다.  

4. 다중 프로그래밍, 다중 프로그램의 정도
동시에 주 메모리 위에 올린 프로세스의 개수가 많다면 다중 프로그래밍의 정도가 높다, 크다 라고 할 수 있다.  

5. 사이클
CPU 클럭 = 1사이클이라고 보면 된다.  
1클럭이 CPU에 공급될 때마다 CPU의 전반적인 상태를 변경할 수 있다.  
