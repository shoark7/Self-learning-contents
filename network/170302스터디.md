##리눅스 커맨드라인 완벽 입문서 27~29

각자 책을 참고하여 필요한 프로그램을 작성하고 토의해보는 것을 제의 한다.  

##점근적 표기, 점근적 분석(Asymptotic notation, Asymptotic analysis)

알고리즘은 입력의 크기가 아주 작으면 알고리즘의 효율성에 상관없이 금방 끝난다.  
알고리즘의 효율성이 문제가 될 때는 입력의 크기가 충분히 클 때다.  
따라서 알고리즘의 수행시간을 분석할 때에는 항상 입력의 크기가 충분히 클 때에 대해서 분석한다.  
즉, **점근적 분석**을 한다.


고등학교에서 배운 lim(극한)를 이용한 분석이 점근적 분석의 한 예다.  
이 절에서는 변수의 크기가 충분히 큰 경우에 변수가 커짐에 따라 함수가 증가하는 비율을 표현하는 방법을 소개한다.  
이를 함수의 **점근적 증가율**이라고 하고 그 표기법을 **점근적 표기법**이라고 한다.  
고등학교 수학에서 배우는 점근적 표기법은 지면상 생략하기로 하고 여기서 간략하게 Big-O표기법을 사용해보면,
lim(n->∞)((2n^2 + 3n)/n) = 2n + 3 = O(n)이다. 이걸 말로 표현해 보면,  
함수 f(n)은 n이 충분히 커짐에 따라 n에 대한 *일차식*의 비율로 증가한다는 뜻이 된다.  


lim표기법에서는 함수의 차수, 계수, 상수항(경우에 따라 제외하기도 하지만)까지 전부 중시하지만,  
Big-O표기법에서는 오직 함수의 차수만을 중시한다.


-> 점근: 점점 가까워짐  
-> 점근법: <수학> 계산을 할 때에, 먼저 어떤 근삿값을 구하고 그것을 이용하여  
더 가까운 근삿값을 구하여 점차 정확도를 높여 가는 방법.  

##Big-O 표기법(Big-O Notation)

알고리즘의 소요시간이 입력의 크기 n에 대해 O(n^2)이라면, 기껏해야 n^2에 비례하는 시간이 소요됨을 뜻한다.  
즉, O(f(n))은 **점근적 증가율**이 f(n)을 넘지 않는 모든 함수들의 집합이다.  
예를 들어, 5n^2 + 4n = O(n^2)이다. 즉, 5n^2의 증가율은 n^2의 증가율과 점근적인 의미에서 같으므로  
5n^2 + 4n = O(n^2)이다. 또한 7n = O(n^2)이라고 해도 된다. 7n의 증가율은 n^2의 증가율보다 더 *작기*때문이다.  
다시 말하면, O(f(n))은 최고차항의 차수가 f(n)과 일치하거나, 더 작은 함수들의 집합이다.  
이는 원래 O(f(n))의 정의와 맞아 떨어진다. Big-O표기는 함수의 **점근적 상한**을 나타낸다.  


Big-O표기법을 자세하게 알아보자.  
O(g(n)) = {f(n)| ∃c > 0, n0 > 0 s.t. ∀n >= n0, f(n) <= cg(n)}
너무 어렵다. 풀어서 말해보자.  


O(g(n)) = {f(n)| 모든 n >= n0에 대하여, f(n) <= cg(n)인 양의 상수 c와 n0가 존재한다.}
조금 더 나아지기는 했지만, 더 직관적으로 표현해 보면...


O(g(n)) = {f(n)| 충분히 큰 모든 n에 대하여 f(n) <= cg(n)인 양수 c가 존재한다.}
즉, O(g(n))은 충분히 큰 n에 대하여 g(n)에 상수만 곱하면 g(n)이 누를 수 있는(더 크거나 같아질 수 있는)  
모든 함수의 집합이다. n^2에 3보다 크거나 같은 상수를 곱하면 n^2이 3n^2보다 크거나 같아질 수 있으므로  
3n^2은 O(n^2)에 속한다. 상수와 관계없이 n^2이 10n보다 크므로 10n은 O(n^2)에 속한다.
(아무 상수나 잡으면 되기 때문이다.) O(n^2)에 속하는 함수의 예로 n^2, nlog(n), n등을 들 수 있다.







(nlog(n))이면 이는 해당 알고리즘의 소요시간이  
입력의 크기 n에 대하여 nlog(n)보다 점근적으로 가파르지는 않게 증가함을 뜻한다.   
O(nlog(n))에는 소요시간이 nlog(n)과 같은 비율로 증가하는지 nlog(n)보다 더 완만하게 증가하는지에 대한 정보는 없다.   
nlog(n)보다는 점근적으로 나쁘지 않다는 것만 확실하다.   
즉, Big-O표기는 **엄밀한 상한**이 될 수도 있고, **여유있는 상한**이 될 수도 있다.   


참고로 최고차항이 n^r이거나 그보다 작은 작은 다항식은 무조건 O(n^r)이다. 


**주의**: Big-O표기법에서 등호(=)는 원래의 등호와는 다른 의미를 지닌다.   
예를 들어, 어떤 함수가 O(x)이면 O(x^2)이므로 O(x) = O(x^2)로 표기할 수 있다.   
하지만, O(x^2) = O(x)와 같이 쓰는 것은 잘못된 표기이다.   

##Big-Omega 표기법(Big-Ω Notation)
Big-Omega표기는 다음과 같이 정의한다.   
Ω(g(n)) = {f(n)| ∃c > 0, n0 > 0 s.t. ∀n >= n0, cg(n) =< f(n)}  
풀어서 말하면 다음과 같다.   

Ω(g(n)) = {f(n)| 모든 n >= n0에 대하여, cg(n) <= f(n)인 양의 상수 c와 n0가 존재한다.}
더 직관적으로 말해서,   

Ω(g(n)) = {f(n)| 충분히 큰 모든 n에 대하여 cg(n) <= f(n)인 양수 c가 존재한다.}
즉, Ω(g(n))은 충분히 큰 n에 대하여 g(n)에 상수만 곱하면 g(n)이 질 수 있는(더 작거나 같아질수 있는)   
모든 함수의 집합이다. n^2에 상수 1을 곱하면(있는 그대로 두면) 항상 n^2이 5n^2보다 작으므로 5n^2 = Ω(n^2)이다.   
4n^3은 충분히 큰 n에 대해서는 상수와 관계없이(아무 상수나 잡으면 된다.)n^2보다 크므로 4n^3 = Ω(n^2)이다.   
Ω(n^2)이 속하는 함수의 예로 n^2, n^2log(n), n^3, 2^n등을 들 수 있다.   
또 이들 앞에 계수가 붙어 있어도 마찬가지다. n이 충분히 크기만 하면, 
넉넉잡아서 이들의 계수보다 작은 상수를 n^2에 곱해버리면 무조건 n^2이 더 작아지기 때문이다.   
이들에 더 낮은 차수의 항이 추가로 붙어 있어도 마찬가지다.   


어떤 알고리즘을 분석해서 소요시간이 Ω(nlog(n))이면 해당 알고리즘의 소요시간은 입력의 크기 n에 대하여  
nlog(n)보다 점근적으로 더 완만하지는 않게 증가함을 뜻한다.   
Ω(nlog(n))에는 소요시간이 nlog(n)과 같은 비율로 증가하는지 nlog(n)보다 더 가파르게 증가하는지에 대한 정보는 없다.   
nlog(n)보다는 점근적으로 좋지 않다는 것만 확실하다.   
즉, Ω-표기는 **엄밀한 하한**이 될 수도 있고, **여유있는 하한**이 될 수도 있다.   


-> Ω-표기로 나타낸 하한과 O-표기로 나타낸 상한이 일치하면 상한과 하한이 일치해서 Θ-표기를 사용할 수 있다.   
참고로 최고차항이 n^r이거나 그보다 **큰** 다항식은 무조건 Ω(n^r)이다.   
##Big-Theta 표기법(Big-Θ Notation)
Θ-표기는 다음과 같이 정의한다.


Θ(g(n)) = O(g(n)) ∩ Ω(g(n))
즉, Θ(g(n))은 O(g(n))과 Ω(g(n))이 동시에 성립하는 모든 함수의 집합을 말한다.
이것은 O(g(n))과 Ω(g(n))의 정의를 합쳐서 다음과 같이 정의하기도 한다.


Θ(g(n)) = {f(n)| ∃c1, c2 > 0, n0 > 0 s.t. ∀n >= n0, c1g(n) =< f(n) =< c2g(n)}
다시 말하면 다음과 같다.


Θ(g(n)) = {f(n)| 충분히 큰 모든 n에 대하여 c1g(n) =< f(n) =< c2g(n)인 양의 상수 c1, c2가 존재한다.}
5n^2 = O(n^2)이고, 5n^2 = Ω(n^2)이므로, 5n^2 = Θ(n^2)이다.
또한, 7n^2 +5= O(n^2)이고, 7n^2 + 5= Ω(n^2)이므로, 7n^2 +5 = Θ(n^2)이다.
즉, 5n^2, 7n^2 + 5는 모두 n^2과 점근적으로 같은 기울기를 갖는다.


이를 통해서 최고차항이 n^r인 다항식은 무조건 Θ(n^r)임을 알 수 있다.


